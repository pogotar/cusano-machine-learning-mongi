{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 3 (2705130436.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    def load_file(filename):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logreg_inference(x, w, b): # z = w.T x + b \n",
    "    \"\"\"Inference step for the logistic regression model.\"\"\"\n",
    "    logit  = (x @ w) + b # no need to transpose becuse there is no transpose for vectors in phyton\n",
    "    p = sigmoid(logit)  # 1 / (1 + np.exp(-z))\n",
    "    return p\n",
    "\n",
    "\n",
    "def cross_entropy(P, Y):\n",
    "    \"\"\"Binary cross-entropy.\"\"\"\n",
    "    return (-Y * np.log(P) - (1 - Y) * np.log(1 - P)).mean()\n",
    "\n",
    "\n",
    "def logreg_train(X, Y, lr, steps):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros(n)\n",
    "    b = 0   # convex function doesn't matter where we start\n",
    "    for step in range(steps):\n",
    "        P = logreg_inference(X, w, b)\n",
    "        if step % 1000 == 0: # to print every thousand cycles\n",
    "            loss = cross_entropy(P, Y)\n",
    "            print(step, loss)\n",
    "        grad_w = (X.T @ (P - Y)) / m  # gradient w.r.t. w\n",
    "        grad_b = (P - Y).mean()       # gradient w.r.t. b\n",
    "        # Gradient descent updates.\n",
    "        \n",
    "        w -= lr * grad_w  # e qui li aggiorno\n",
    "        b -= lr * grad_b\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def load_file(filename):\n",
    "    data = np.loadtxt(filename)\n",
    "    X = data[:, :-1] # take all rows and all columns except last one\n",
    "    Y = data[:, -1]\n",
    "    return X, Y\n",
    "\n",
    "X, Y = load_file(\"titanic-train.txt\")\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "w, b = logreg_train(X, Y, 0.001, 10000) # x, y, learning rate, step\n",
    "print(\"w=\", w)\n",
    "print(\"b=\", b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
